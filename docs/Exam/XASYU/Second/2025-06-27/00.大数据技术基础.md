# 大数据技术基础

- 时间：10:30 - 12:30
- 地点：中心楼 612-614
- 监考老师：贺飞、习子辰

## 第一大题

::: tip 情景

某城市的共享单车运营商管理着覆盖全城的十万级单车，在潮汐通勤、商圈热点与随机骑行需求的交织下，正面临双重运营挑战：早晚高峰地铁站周边单车积压与写字楼区域“无车可用”的供需错配，以及用户因找车耗时、车辆故障导致的体验流失。为破解这一困境，企业决定构建基于大数据的智能调度体系与实时场景数据的融合分析，实现动态调度策略优化，同时依托用户骑行偏好搭建个性化服务模型，在提升单车日均使用频次的同时，将用户找车时间缩短。这一数字化转型不仅需攻克千万级数据的实时处理难题，更要在效率提升与用户体验之间找到动态平衡点。

:::

### 1.1

> 根据材料。闸述该单车运营商如何获取用户数据？这些数据符合大数据的哪些特征？

**数据获取方式**：

- **用户骑行数据**：通过单车内置的 GPS 和智能锁记录骑行轨迹、时间、起点/终点位置。
- **用户注册信息**：APP 注册时收集的用户年龄、性别、职业等。
- **用户行为数据**：APP 搜索记录、找车时间、预约/取消行为。
- **车辆状态数据**：单车传感器检测的故障信息（如刹车损坏、电量不足）。
- **外部数据**：天气数据、地铁/公交时刻表、商圈活动信息等。

**大数据特征（4V）**：

- **Volume（大量）**：十万级单车每天产生海量 GPS 轨迹、用户行为数据。
- **Velocity（高速）**：实时采集骑行数据，需快速处理调度需求。
- **Variety（多样）**：结构化（用户信息）、半结构化（GPS 轨迹）、非结构化（用户反馈文本）。
- **Value（价值）**：分析后可优化调度、提升用户体验。

### 1.2

> 结合案例。阐述共享单车运营商应用大数频技术过程中将会面临哪些挑战。

- **数据实时处理**：需处理千万级 GPS 数据流，确保调度决策的时效性。
- **数据质量**：GPS 信号漂移、用户误操作导致的数据异常。
- **隐私保护**：用户轨迹数据涉及隐私，需合规存储和使用。
- **算法优化**：动态调度需平衡供需，避免“无车可用”或“车辆堆积”。
- **系统稳定性**：高并发访问时，大数据平台需保证高可用性。

## 第二大题

::: tip 情景

某在线学习平台收集了计算机专业几门核心课程的用户学习数据，存储在 `study.csv` 文件中，包含用户名 `user`、课程 ID `courseid`、学习时长 `lt`、课后测验得分 `score` 等字段，数据量约 80 万条。经初步查看，发现收集到的数据中存在异常、缺失、重复等问题，需要对这些数据进行预处理，以便后续的数据分析。

:::

### 2.1

> 在处理学习时长 `lt` 字段的缺失值时，可以用那几种填充方法？若使用均值填充法，可能存在哪些潜在问题？请结合数据实际情况说明。

**填充方法**：

- **均值填充**：适用于数据分布较均匀时。
- **中位数填充**：适用于存在极端值时。
- **众数填充**：适用于分类数据或特定模式的数据。
- **回归预测填充**：利用其他字段（如 `score`）预测缺失值。

**均值填充的问题**：

- 若学习时长分布不均匀（如部分用户学习时间极长），均值可能偏离真实情况。
- 掩盖真实的数据分布特征，影响后续分析（如异常检测）。

### 2.2

> 若发现用户名 `user` 字段存在部分全为空格的记录，从数据收集和使用的角度，分析这些记录产生的际因，并说明应如何处理这类数据。

**可能原因**：

- 数据采集时未强制校验用户输入，导致提交空值。
- 系统故障或 API 传输错误，未正确记录用户名。

**处理方法**：

- **删除记录**：若缺失比例低且不影响分析。
- **填充默认值**：如 `"Unknown"`，但需标注为缺失数据。
- **数据溯源**：检查采集流程，修复校验逻辑。

### 2.3

> 若测试得分中存在异常值，请利用 Pyton 编写程序，找出课后测验得分 `scoee` 字段中小 0 或大于 100 的异常数据，并将这些异富数的学习时长 `lt` 设置为缺失值 `NaN`，最后输出处理后的数据。

```python
import pandas as pd
import numpy as np

# 读取数据
study = pd.read_csv("study.csv")

# 找出 score < 0 或 > 100 的异常值，并将对应 lt 设为 NaN
study.loc[(study["score"] < 0) | (study["score"] > 100), "lt"] = np.nan

# 输出处理后的数据
print(study)
```

## 第三大题

::: tip 情景

材料一：A 市交通局拟利用大数据可视化技术缓解拥堵，整合出租车 GPS、地铁刷卡、路口监控和天气数据，构建实时交通态势感知系统，为市民提供出行建议，并辅助交通管理决策。

材料二：某科技公司计划对泰坦尼克号乘客数据（数据集 `titanic.csv` 有 891 条记录，图 1 展示了部分数据）进行可视化分析，使用 Python 的 `matplotlib` 库和 `seaborn` 库来绘制箱形图，如图 2 所示，从年龄、性别、舱位等级等多维度挖掘群体特征，帮助公众更好地理解乘船人员的构成情况。

:::

### 3.1

> 结合材料一，请你为该交通管理局设计出数据可视化的流程。

1. **数据采集**：整合出租车 GPS、地铁刷卡、路口监控、天气数据。
2. **数据清洗**：处理缺失值、异常值（如 GPS 漂移）。
3. **数据存储**：使用分布式存储（如 HDFS）或时序数据库（如 InfluxDB）。
4. **数据分析**：计算拥堵指数、出行热点区域。
5. **可视化设计**：选择合适图表（如热力图、折线图）。
6. **交互优化**：提供动态筛选（如时间段、区域）。
7. **部署应用**：集成到交通管理平台或公众出行 APP。

### 3.2

> 结合材料一，请你为该交通管理局推荐可采用的可视化图表，并分析选择依据。

- **热力图**：展示路口/地铁站拥堵程度（基于 GPS 密度）。
- **折线图**：显示全天交通流量变化趋势。
- **地理信息图（GIS）**：叠加实时路况和事故点。
- **散点图**：分析天气（如降雨）与拥堵的关联性。

**选择依据**：

- 热力图适合空间密度分析，折线图适合时间趋势，GIS 适合地理位置关联。

### 3.3

> 结合材料二，以下是该公司设计的代码框架，请你根据注释提示在编号横线处将代码补充完整、并分析箱形图所表达的关键数据特征。

::: code-group

```python [修改前]
import pandas as pd
# 导入第三方库 - 统计分析
import seaborn as sns
# 导入第三方库 - 统计绘图
import '''______''' as plt
# 导入第三方库 - 基础绘图

sns.set_style('darkgrid')
# 改置 seaborn 风格

sns.set(font='SimHei')
# 设置中文字体

titanic = '''______'''("titanic.csv")
# 读取泰坦尼克数据集

titanic['sex']= ["男" if i == "male" else "女" for i in titanic['sex']] # 重命名性别

# 重命名舱位等级
titanic['class'] = ['1' if i == "First" else "2" if i == "Second" else "3" for i in titanic['class']]

# 对数据集列名重新命名
titanic = titanic.rename(columns={"class":"舱位等级", "age":"乘客年龄", "sex":"乘客性别"})

# 生成箱形图
sns.'''______'''(x = "舱位等级", y = "乘客年龄", hue = "乘客性别", '''______''')
# 传入 X 轴数据，舱位等级
# 传入 Y 轴数据，乘客年龄
# 传入 hue 参数，乘客性別
# 传入数据集

# 显示绘制的图形
'''______'''
```

```python [修改后]
import pandas as pd
# 导入第三方库 - 统计分析
import seaborn as sns
# 导入第三方库 - 统计绘图
import matplotlib.pyplot as plt  # 填空
# 导入第三方库 - 基础绘图

sns.set_style('darkgrid')
# 改置 Seaborn 风格

sns.set(font='SimHei')
# 设置中文字体

titanic = pd.read_csv("titanic.csv")  # 填空
# 读取泰坦尼克数据集

titanic['sex']= ["男" if i == "male" else "女" for i in titanic['sex']] # 重命名性别

# 重命名舱位等级
titanic['class'] = ['1' if i == "First" else "2" if i == "Second" else "3" for i in titanic['class']]

# 对数据集列名重新命名
titanic = titanic.rename(columns={"class":"舱位等级", "age":"乘客年龄", "sex":"乘客性别"})

# 生成箱形图
sns.boxplot(x = "舱位等级", y = "乘客年龄", hue = "乘客性别", data=titanic)  # 填空
# 传入 X 轴数据，舱位等级
# 传入 Y 轴数据，乘客年龄
# 传入 hue 参数，乘客性別
# 传入数据集

# 显示绘制的图形
plt.show()  # 填空
```

:::

- 填空部分
  - 缺失的导入库应该是 `matplotlib.pyplot`
  - 读取数据的函数应该是 `pd.read_csv`
  - 箱形图的函数应该是 `boxplot`
  - 最后一个参数应该是 `data=titanic`
  - 显示绘制的图形 `plt.show()`

- 箱形图关键特征
  - **舱位等级**：1 等舱乘客年龄中位数较高，3 等舱年龄分布更分散。
  - **性别差异**：女性在 1/2 等舱年龄较高，男性在 3 等舱更多年轻人。
  - **异常值**：部分高龄乘客（如 1 等舱男性）可能为特殊群体。

## 第四大题

::: tip 情景

某连锁超市“惠民优选”计划分析 2024 年各门店的商品销售情况，以优化 2024 年采购策略。数据部门收集了原始销售记录表 `sales_raw.csv`，包含字段：`订单 ID`，`商品名称_销量`，`门店编号`，`销售日期`，`顾客评分`（示例：`A001, 苹果_15, STO03, 2023-05-10, 4.5`）。但数据存在格式混乱、信息未拆分等问题，需进行处理与分析。

:::

### 4.1

> 超市需将分散在各门店的每日销售数据汇总到 HDFS 中存储。请说明这些销售数据属于哪种数据来源类型？设计一种适合该场景的低频率增量采集方法 (文字说明)。

**数据类型**：结构化数据（CSV 格式的销售记录）。

**增量采集方法**：

- 每日定时（如凌晨）通过 ETL 工具（如 Sqoop）将各门店 CSV 文件增量同步到 HDFS。
- 使用 `last_modified_time` 判断新增文件，避免重复采集。

### 4.2

> 针对字段 `商品名称_销量`（示例：`苹果_15`），应使用什么顶处理操作将其拆分为商品名称租销鼠两个独立字段？并写出该操作在 Pythoa pandas 中的核心函数名 (无需写完整代码)。

**核心函数**：

```python
df[['商品名称', '销量']] = df['商品名称_销量'].str.split('_', expand=True)
```

### 4.3

> 为分析“水果类商品在 2024 年 Q3 的销赋趋势”，应选择哪种基础图表类型？说明选择理由。并指出需从数据中提取的两个关键字段。

**图表类型****：折线图**（展示时间趋势）或 **柱状图**（对比不同水果销量）。

**选择理由**：折线图能清晰反映销量随时间的变化趋势。

**关键字段**：

- `销售日期`（筛选 2024-Q3）
- `商品名称`（筛选水果类，如苹果、香蕉）
